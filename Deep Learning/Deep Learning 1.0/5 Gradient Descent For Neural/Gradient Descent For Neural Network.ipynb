{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement Gradient Descent For Neural Network (or Logistic Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting if a person would buy life insurnace based on his age using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordibility</th>\n",
       "      <th>bought_insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  affordibility  bought_insurance\n",
       "0   22              1                 0\n",
       "1   25              0                 0\n",
       "2   47              1                 1\n",
       "3   52              0                 0\n",
       "4   46              1                 1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"insurance_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Split train and test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['age','affordibility']],df.bought_insurance,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing: Scale the data so that both age and affordibility are in same scaling range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_train.copy()\n",
    "X_train_scaled['age'] = X_train_scaled['age'] / 100\n",
    "\n",
    "X_test_scaled = X_test.copy()\n",
    "X_test_scaled['age'] = X_test_scaled['age'] / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Building: First build a model in keras/tensorflow and see what weights and bias values it comes up with. We will than try to reproduce same weights and bias in our plain python implementation of gradient descent. Below is the architecture of our simple neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emon1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 890ms/step - accuracy: 0.4545 - loss: 0.7334\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.4545 - loss: 0.7330\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.4545 - loss: 0.7326\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.4545 - loss: 0.7321\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.4545 - loss: 0.7317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x24792e6c150>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(1, input_shape=(2,), activation='sigmoid', kernel_initializer='ones', bias_initializer='zeros')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.6667 - loss: 0.6505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6504672169685364, 0.6666666865348816]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.8245093 ],\n",
       "       [0.76298267],\n",
       "       [0.8157031 ],\n",
       "       [0.8096446 ],\n",
       "       [0.8216113 ],\n",
       "       [0.8096446 ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5     1\n",
       "10    0\n",
       "24    1\n",
       "4     1\n",
       "25    1\n",
       "27    0\n",
       "Name: bought_insurance, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get the value of weights and bias from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef, intercept = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.9950013],\n",
       "        [0.995001 ]], dtype=float32),\n",
       " array([-0.00499932], dtype=float32))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef, intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999847700205"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "        import math\n",
    "        return 1 / (1 + math.exp(-x))\n",
    "sigmoid(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  affordibility\n",
       "5    56              1\n",
       "10   18              1\n",
       "24   50              1\n",
       "4    46              1\n",
       "25   54              1\n",
       "27   46              1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of model.predict, write our own prediction function that uses w1,w2 and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emon1\\AppData\\Local\\Temp\\ipykernel_6860\\396317115.py:3: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return 1 / (1 + math.exp(-x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8111733421999793"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prediction_function(age, affordibility):\n",
    "    weighted_sum = coef[0]*age + coef[1]*affordibility + intercept\n",
    "    return sigmoid(weighted_sum)\n",
    "\n",
    "prediction_function(.47, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emon1\\AppData\\Local\\Temp\\ipykernel_6860\\396317115.py:3: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return 1 / (1 + math.exp(-x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7629826512432166"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_function(.18, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we start implementing gradient descent in plain python. Again the goal is to come up with same w1, w2 and bias that keras model calculated. We want to show how keras/tensorflow would have computed these values internally using gradient descent\n",
    "\n",
    "First write couple of helper routines such as sigmoid and log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99999386, 0.5       , 0.73105858])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid_numpy(X):\n",
    "   return 1/(1+np.exp(-X))\n",
    "\n",
    "sigmoid_numpy(np.array([12,0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(y_true, y_predicted):\n",
    "    epsilon = 1e-15\n",
    "    y_predicted_new = [max(i,epsilon) for i in y_predicted]\n",
    "    y_predicted_new = [min(i,1-epsilon) for i in y_predicted_new]\n",
    "    y_predicted_new = np.array(y_predicted_new)\n",
    "    return -np.mean(y_true*np.log(y_predicted_new)+(1-y_true)*np.log(1-y_predicted_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right now comes the time to implement our final gradient descent function !! yay !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(age, affordability, y_true, epochs, loss_thresold):\n",
    "    w1 = w2 = 1\n",
    "    bias = 0\n",
    "    rate = 0.5\n",
    "    n = len(age)\n",
    "    for i in range(epochs):\n",
    "        weighted_sum = w1 * age + w2 * affordability + bias\n",
    "        y_predicted = sigmoid_numpy(weighted_sum)\n",
    "        loss = log_loss(y_true, y_predicted)\n",
    "\n",
    "        w1d = (1/n)*np.dot(np.transpose(age),(y_predicted-y_true)) \n",
    "        w2d = (1/n)*np.dot(np.transpose(affordability),(y_predicted-y_true)) \n",
    "\n",
    "        bias_d = np.mean(y_predicted-y_true)\n",
    "        w1 = w1 - rate * w1d\n",
    "        w2 = w2 - rate * w2d\n",
    "        bias = bias - rate * bias_d\n",
    "\n",
    "        print (f'Epoch:{i}, w1:{w1}, w2:{w2}, bias:{bias}, loss:{loss}')\n",
    "\n",
    "        if loss<=loss_thresold:\n",
    "            break\n",
    "\n",
    "    return w1, w2, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, w1:0.9730107808384282, w2:0.9448358772697057, bias:-0.1297635684840324, loss:0.733398669288911\n",
      "Epoch:1, w1:0.9523123704874401, w2:0.8993433767269012, bias:-0.24291470236225088, loss:0.6949990436123248\n",
      "Epoch:2, w1:0.9373944591510792, w2:0.8629451763708244, bias:-0.34088139295067477, loss:0.6666256014135518\n",
      "Epoch:3, w1:0.9276267308727877, w2:0.8347747513761317, bias:-0.42537054048700623, loss:0.6460202208408456\n",
      "Epoch:4, w1:0.9223355641927409, w2:0.813819777827982, bias:-0.4981722645765692, loss:0.6311935366113732\n",
      "Epoch:5, w1:0.9208621274173802, w2:0.799039468429279, bias:-0.5610158544198987, loss:0.620530613146006\n",
      "Epoch:6, w1:0.92259867515373, w2:0.7894436952684669, bias:-0.6154826989758739, loss:0.612797075390602\n",
      "Epoch:7, w1:0.9270064314976109, w2:0.7841369663598711, bias:-0.6629658579691459, loss:0.6070898816753098\n",
      "Epoch:8, w1:0.933620625363704, w2:0.7823364760902722, bias:-0.7046613775739041, loss:0.6027688433521677\n",
      "Epoch:9, w1:0.9420478069825752, w2:0.7833737107592609, bias:-0.7415781734332123, loss:0.5993901123119486\n",
      "Epoch:10, w1:0.9519592146968441, w2:0.7866869616782799, bias:-0.774557036327638, loss:0.5966507142438551\n",
      "Epoch:11, w1:0.9630826072056028, w2:0.7918096505115648, bias:-0.8042928349445652, loss:0.5943460285336464\n",
      "Epoch:12, w1:0.9751939513935453, w2:0.7983574109696847, bias:-0.8313565829300733, loss:0.5923388309808243\n",
      "Epoch:13, w1:0.9881096801729436, w2:0.8060155315999776, bias:-0.8562157132273208, loss:0.5905374913452726\n",
      "Epoch:14, w1:1.001679827897562, w2:0.8145275326495423, bias:-0.8792518935906187, loss:0.5888809529001704\n",
      "Epoch:15, w1:1.0157821235155498, w2:0.8236851687626293, bias:-0.9007762596436841, loss:0.5873285371011524\n",
      "Epoch:16, w1:1.0303170044811363, w2:0.8333198890754949, bias:-0.9210422133404373, loss:0.5858530933741247\n",
      "Epoch:17, w1:1.0452034611410472, w2:0.8432956573485383, bias:-0.9402560517682915, loss:0.5844364286135869\n",
      "Epoch:18, w1:1.060375603113473, w2:0.8535029802266779, bias:-0.9585857250058174, loss:0.5830662724502026\n",
      "Epoch:19, w1:1.0757798391691056, w2:0.8638539773448468, bias:-0.9761680134724035, loss:0.5817342689491607\n",
      "Epoch:20, w1:1.091372570724347, w2:0.8742783329960613, bias:-0.9931143879118444, loss:0.5804346505678077\n",
      "Epoch:21, w1:1.1071183110331695, w2:0.8847199843470374, bias:-1.0095157811886537, loss:0.5791633638748389\n",
      "Epoch:22, w1:1.1229881547805753, w2:0.8951344196960165, bias:-1.025446466748136, loss:0.5779174936108394\n",
      "Epoch:23, w1:1.1389585347000986, w2:0.9054864788981888, bias:-1.0409672068601123, loss:0.5766948834106514\n",
      "Epoch:24, w1:1.1550102124869495, w2:0.9157485653393206, bias:-1.0561278057992742, loss:0.575493886001596\n",
      "Epoch:25, w1:1.1711274604874375, w2:0.9258991941090485, bias:-1.0709691791534295, loss:0.5743131985769087\n",
      "Epoch:26, w1:1.1872973984473758, w2:0.9359218141721081, bias:-1.0855250302857875, loss:0.5731517541762906\n",
      "Epoch:27, w1:1.2035094561232347, w2:0.9458038534533761, bias:-1.0998232082078332, loss:0.5720086498879151\n",
      "Epoch:28, w1:1.2197549379598647, w2:0.9555359450410175, bias:-1.1138868072863697, loss:0.5708830992604106\n",
      "Epoch:29, w1:1.2360266704812617, w2:0.9651113004066626, bias:-1.1277350578624612, loss:0.5697744006379503\n",
      "Epoch:30, w1:1.2523187166787795, w2:0.9745252018772198, bias:-1.1413840475917953, loss:0.5686819159742054\n",
      "Epoch:31, w1:1.268626144650011, w2:0.9837745917864887, bias:-1.154847305767149, loss:0.5676050565484994\n",
      "Epoch:32, w1:1.2849448401582553, w2:0.9928577399780764, bias:-1.1681362767483603, loss:0.5665432732341448\n",
      "Epoch:33, w1:1.3012713547460688, w2:1.0017739747895198, bias:-1.1812607036466292, loss:0.5654960497745037\n",
      "Epoch:34, w1:1.3176027826296064, w2:1.0105234654609696, bias:-1.1942289393746528, loss:0.56446289805138\n",
      "Epoch:35, w1:1.3339366608918426, w2:1.0191070461973462, bias:-1.2070481989061062, loss:0.5634433546778084\n",
      "Epoch:36, w1:1.3502708885386834, w2:1.0275260739676497, bias:-1.2197247639429636, loss:0.5624369784755926\n",
      "Epoch:37, w1:1.366603660828651, w2:1.0357823136291027, bias:-1.2322641490492987, loss:0.5614433485479201\n",
      "Epoch:38, w1:1.3829334159719349, w2:1.0438778451826558, bias:-1.2446712365794825, loss:0.560462062755975\n",
      "Epoch:39, w1:1.3992587918488417, w2:1.0518149889537673, bias:-1.256950386329154, loss:0.5594927364732954\n",
      "Epoch:40, w1:1.4155785908459702, w2:1.0595962452919914, bias:-1.2691055247056762, loss:0.5585350015342625\n",
      "Epoch:41, w1:1.4318917512710245, w2:1.067224246030385, bias:-1.2811402172997557, loss:0.557588505321171\n",
      "Epoch:42, w1:1.4481973241004336, w2:1.074701715469961, bias:-1.2930577279999986, loss:0.5566529099528232\n",
      "Epoch:43, w1:1.4644944540511338, w2:1.0820314390788324, bias:-1.3048610671938237, loss:0.5557278915497643\n",
      "Epoch:44, w1:1.4807823641597508, w2:1.0892162384393203, bias:-1.316553031114222, loss:0.5548131395593191\n",
      "Epoch:45, w1:1.4970603432076324, w2:1.0962589512545375, bias:-1.3281362340003928, loss:0.5539083561289008\n",
      "Epoch:46, w1:1.5133277354557853, w2:1.1031624154512722, bias:-1.3396131344235798, loss:0.5530132555195802\n",
      "Epoch:47, w1:1.529583932255417, w2:1.1099294565984805, bias:-1.350986056873145, loss:0.5521275635542389\n",
      "Epoch:48, w1:1.545828365182052, w2:1.116562878008513, bias:-1.3622572094904914, loss:0.5512510170961811\n",
      "Epoch:49, w1:1.5620605004078087, w2:1.123065453007963, bias:-1.3734286986705102, loss:0.5503833635551271\n",
      "Epoch:50, w1:1.5782798340803654, w2:1.1294399189620585, bias:-1.3845025411142555, loss:0.5495243604182088\n",
      "Epoch:51, w1:1.59448588852083, w2:1.1356889727151864, bias:-1.3954806738064005, loss:0.5486737748040719\n",
      "Epoch:52, w1:1.610678209088136, w2:1.1418152671738828, bias:-1.406364962301806, loss:0.5478313830385151\n",
      "Epoch:53, w1:1.6268563615862695, w2:1.1478214088103376, bias:-1.417157207633215, loss:0.5469969702503366\n",
      "Epoch:54, w1:1.643019930113885, w2:1.153709955906377, bias:-1.4278591520934794, loss:0.5461703299862178\n",
      "Epoch:55, w1:1.6591685152747295, w2:1.1594834173919073, bias:-1.438472484098189, loss:0.545351263843608\n",
      "Epoch:56, w1:1.6753017326825763, w2:1.165144252159391, bias:-1.4489988422960423, loss:0.544539581120659\n",
      "Epoch:57, w1:1.691419211706788, w2:1.1706948687583258, bias:-1.4594398190630091, loss:0.5437350984823401\n",
      "Epoch:58, w1:1.7075205944146867, w2:1.1761376253918643, bias:-1.4697969634909784, loss:0.5429376396419243\n",
      "Epoch:59, w1:1.723605534675082, w2:1.1814748301524776, bias:-1.480071783960968, loss:0.5421470350570862\n",
      "Epoch:60, w1:1.7396736973939504, w2:1.1867087414455357, bias:-1.490265750374258, loss:0.5413631216398995\n",
      "Epoch:61, w1:1.7557247578586386, w2:1.191841568559414, bias:-1.500380296101217, loss:0.5405857424800596\n",
      "Epoch:62, w1:1.7717584011713494, w2:1.1968754723486328, bias:-1.5104168196965566, loss:0.5398147465806983\n",
      "Epoch:63, w1:1.7877743217562239, w2:1.201812566002958, bias:-1.5203766864207715, loss:0.5390499886061811\n",
      "Epoch:64, w1:1.8037722229272257, w2:1.206654915880601, bias:-1.5302612296002327, loss:0.5382913286413235\n",
      "Epoch:65, w1:1.81975181650639, w2:1.2114045423878956, bias:-1.5400717518524667, loss:0.5375386319614736\n",
      "Epoch:66, w1:1.835712822483907, w2:1.2160634208912655, bias:-1.5498095261983242, loss:0.5367917688129539\n",
      "Epoch:67, w1:1.851654968713073, w2:1.220633482650096, bias:-1.5594757970788165, loss:0.5360506142033636\n",
      "Epoch:68, w1:1.867577990634408, w2:1.2251166157613893, bias:-1.569071781291191, loss:0.5353150477012839\n",
      "Epoch:69, w1:1.8834816310242686, w2:1.2295146661089302, bias:-1.5785986688562212, loss:0.5345849532449343\n",
      "Epoch:70, w1:1.8993656397641312, w2:1.2338294383111807, bias:-1.5880576238265494, loss:0.5338602189593673\n",
      "Epoch:71, w1:1.9152297736274029, w2:1.2380626966633415, bias:-1.5974497850441958, loss:0.5331407369817938\n",
      "Epoch:72, w1:1.931073796081176, w2:1.2422161660700004, bias:-1.606776266853935, loss:0.5324264032946633\n",
      "Epoch:73, w1:1.946897477100802, w2:1.2462915329655888, bias:-1.6160381597780775, loss:0.5317171175661338\n",
      "Epoch:74, w1:1.9627005929955301, w2:1.2502904462205082, bias:-1.6252365311572623, loss:0.531012782997587\n",
      "Epoch:75, w1:1.9784829262437584, w2:1.2542145180313224, bias:-1.6343724257610848, loss:0.5303133061778634\n",
      "Epoch:76, w1:1.9942442653367012, w2:1.258065324793821, bias:-1.6434468663717623, loss:0.529618596943902\n",
      "Epoch:77, w1:2.0099844046294693, w2:1.2618444079581124, bias:-1.6524608543435155, loss:0.528928568247491\n",
      "Epoch:78, w1:2.025703144198736, w2:1.2655532748651703, bias:-1.6614153701399248, loss:0.5282431360278453\n",
      "Epoch:79, w1:2.0414002897062935, w2:1.2691933995644833, bias:-1.6703113738511701, loss:0.5275622190897432\n",
      "Epoch:80, w1:2.0570756522679132, w2:1.2727662236126294, bias:-1.6791498056927774, loss:0.5268857389869659\n",
      "Epoch:81, w1:2.0727290483270226, w2:1.2762731568527426, bias:-1.6879315864872588, loss:0.5262136199107977\n",
      "Epoch:82, w1:2.0883602995327823, w2:1.279715578174944, bias:-1.6966576181298414, loss:0.5255457885833551\n",
      "Epoch:83, w1:2.1039692326222084, w2:1.2830948362579035, bias:-1.7053287840393145, loss:0.5248821741555223\n",
      "Epoch:84, w1:2.1195556793060377, w2:1.286412250291761, bias:-1.713945949594898, loss:0.5242227081092875\n",
      "Epoch:85, w1:2.135119476158079, w2:1.2896691106826947, bias:-1.7225099625599174, loss:0.5235673241642753\n",
      "Epoch:86, w1:2.150660464507822, w2:1.2928666797394592, bias:-1.7310216534929843, loss:0.52291595818829\n",
      "Epoch:87, w1:2.1661784903361077, w2:1.2960061923422483, bias:-1.739481836147303, loss:0.5222685481116834\n",
      "Epoch:88, w1:2.1816734041736954, w2:1.2990888565942607, bias:-1.7478913078586562, loss:0.5216250338453802\n",
      "Epoch:89, w1:2.197145061002564, w2:1.302115854456359, bias:-1.7562508499225735, loss:0.5209853572023904\n",
      "Epoch:90, w1:2.2125933201598222, w2:1.305088342365223, bias:-1.7645612279611353, loss:0.5203494618226588\n",
      "Epoch:91, w1:2.2280180452441045, w2:1.3080074518354068, bias:-1.772823192279831, loss:0.5197172931010972\n",
      "Epoch:92, w1:2.2434191040243396, w2:1.3108742900457035, bias:-1.7810374782148513, loss:0.5190887981186587\n",
      "Epoch:93, w1:2.258796368350803, w2:1.3136899404102318, bias:-1.789204806471171, loss:0.5184639255763203\n",
      "Epoch:94, w1:2.274149714068352, w2:1.3164554631346443, bias:-1.797325883451751, loss:0.5178426257318423\n",
      "Epoch:95, w1:2.2894790209317715, w2:1.3191718957578609, bias:-1.805401401578166, loss:0.517224850339184\n",
      "Epoch:96, w1:2.3047841725231475, w2:1.3218402536797207, bias:-1.81343203960295, loss:0.5166105525904547\n",
      "Epoch:97, w1:2.3200650561712, w2:1.3244615306749405, bias:-1.8214184629139263, loss:0.5159996870602922\n",
      "Epoch:98, w1:2.3353215628725104, w2:1.32703669939376, bias:-1.8293613238307873, loss:0.5153922096525588\n",
      "Epoch:99, w1:2.350553587214578, w2:1.3295667118496428, bias:-1.8372612618941615, loss:0.5147880775492566\n",
      "Epoch:100, w1:2.365761027300655, w2:1.3320524998944012, bias:-1.8451189041474032, loss:0.5141872491615603\n",
      "Epoch:101, w1:2.3809437846762944, w2:1.3344949756810929, bias:-1.8529348654113285, loss:0.5135896840828801\n",
      "Epoch:102, w1:2.3961017642575695, w2:1.3368950321150381, bias:-1.8607097485521045, loss:0.5129953430438617\n",
      "Epoch:103, w1:2.411234874260907, w2:1.3392535432932928, bias:-1.8684441447425015, loss:0.5124041878692446\n",
      "Epoch:104, w1:2.426343026134495, w2:1.3415713649329022, bias:-1.8761386337166963, loss:0.5118161814364904\n",
      "Epoch:105, w1:2.4414261344912127, w2:1.343849334788254, bias:-1.8837937840188188, loss:0.5112312876361139\n",
      "Epoch:106, w1:2.456484117043044, w2:1.3460882730578403, bias:-1.8914101532454193, loss:0.5106494713336359\n",
      "Epoch:107, w1:2.4715168945369337, w2:1.348288982780724, bias:-1.8989882882820301, loss:0.5100706983330914\n",
      "Epoch:108, w1:2.4865243906920456, w2:1.350452250223006, bias:-1.9065287255339904, loss:0.5094949353420263\n",
      "Epoch:109, w1:2.501506532138384, w2:1.35257884525457, bias:-1.914031991151692, loss:0.5089221499379186\n",
      "Epoch:110, w1:2.516463248356744, w2:1.354669521716382, bias:-1.9214986012504054, loss:0.5083523105359622\n",
      "Epoch:111, w1:2.531394471619952, w2:1.3567250177786105, bias:-1.9289290621248332, loss:0.5077853863581561\n",
      "Epoch:112, w1:2.5463001369353693, w2:1.358746056289822, bias:-1.9363238704585395, loss:0.5072213474036443\n",
      "Epoch:113, w1:2.5611801819886173, w2:1.3607333451175032, bias:-1.9436835135283916, loss:0.506660164420252\n",
      "Epoch:114, w1:2.5760345470885007, w2:1.3626875774801555, bias:-1.951008469404154, loss:0.5061018088771669\n",
      "Epoch:115, w1:2.590863175113092, w2:1.36460943227119, bias:-1.9582992071433636, loss:0.5055462529387199\n",
      "Epoch:116, w1:2.6056660114569525, w2:1.3664995743748571, bias:-1.9655561869816132, loss:0.5049934694392149\n",
      "Epoch:117, w1:2.6204430039794575, w2:1.3683586549744289, bias:-1.9727798605183697, loss:0.5044434318587684\n",
      "Epoch:118, w1:2.635194102954202, w2:1.3701873118528476, bias:-1.9799706708984428, loss:0.5038961143001116\n",
      "Epoch:119, w1:2.6499192610194564, w2:1.37198616968605, bias:-1.9871290529892207, loss:0.5033514914663184\n",
      "Epoch:120, w1:2.664618433129649, w2:1.3737558403291688, bias:-1.9942554335537879, loss:0.5028095386394186\n",
      "Epoch:121, w1:2.679291576507848, w2:1.375496923095803, bias:-2.001350231420029, loss:0.5022702316598591\n",
      "Epoch:122, w1:2.6939386505992227, w2:1.377210005030553, bias:-2.0084138576458286, loss:0.501733546906781\n",
      "Epoch:123, w1:2.7085596170254527, w2:1.3788956611749963, bias:-2.015446715680466, loss:0.5011994612790734\n",
      "Epoch:124, w1:2.7231544395400733, w2:1.3805544548272892, bias:-2.0224492015223055, loss:0.5006679521771781\n",
      "Epoch:125, w1:2.737723083984724, w2:1.382186937795561, bias:-2.0294217038728792, loss:0.5001389974856061\n",
      "Epoch:126, w1:2.752265518246285, w2:1.3837936506452722, bias:-2.036364604287452, loss:0.49961257555614574\n",
      "Epoch:127, w1:2.76678171221488, w2:1.385375122940698, bias:-2.0432782773221647, loss:0.499088665191727\n",
      "Epoch:128, w1:2.781271637742722, w2:1.386931873480694, bias:-2.0501630906778394, loss:0.49856724563091726\n",
      "Epoch:129, w1:2.7957352686037877, w2:1.388464410528896, bias:-2.057019405340532, loss:0.49804829653302307\n",
      "Epoch:130, w1:2.8101725804542963, w2:1.3899732320385054, bias:-2.0638475757189187, loss:0.4975317979637733\n",
      "Epoch:131, w1:2.8245835507939763, w2:1.3914588258718017, bias:-2.070647949778591, loss:0.4970177303815579\n",
      "Epoch:132, w1:2.8389681589281026, w2:1.3929216700145197, bias:-2.0774208691733422, loss:0.496506074624203\n",
      "Epoch:133, w1:2.853326385930287, w2:1.394362232785232, bias:-2.0841666693735204, loss:0.49599681189625594\n",
      "Epoch:134, w1:2.867658214606001, w2:1.3957809730398627, bias:-2.090885679791518, loss:0.49548992375676454\n",
      "Epoch:135, w1:2.8819636294568216, w2:1.3971783403714633, bias:-2.0975782239044736, loss:0.4949853921075267\n",
      "Epoch:136, w1:2.8962426166453756, w2:1.398554775305373, bias:-2.1042446193742546, loss:0.49448319918179295\n",
      "Epoch:137, w1:2.910495163960974, w2:1.3999107094898848, bias:-2.1108851781647853, loss:0.4939833275334031\n",
      "Epoch:138, w1:2.9247212607859168, w2:1.4012465658825304, bias:-2.1175002066567905, loss:0.493485760026341\n",
      "Epoch:139, w1:2.9389208980624533, w2:1.4025627589321028, bias:-2.124090005760014, loss:0.49299047982468647\n",
      "Epoch:140, w1:2.9530940682603894, w2:1.4038596947565214, bias:-2.130654871022979, loss:0.49249747038295505\n",
      "Epoch:141, w1:2.967240765345319, w2:1.4051377713166482, bias:-2.137195092740343, loss:0.49200671543680274\n",
      "Epoch:142, w1:2.981360984747471, w2:1.4063973785861592, bias:-2.143710956057917, loss:0.49151819899408655\n",
      "Epoch:143, w1:2.995454723331161, w2:1.40763889871757, bias:-2.150202741075391, loss:0.4910319053262642\n",
      "Epoch:144, w1:3.0095219793648273, w2:1.408862706204516, bias:-2.156670722946838, loss:0.49054781896011845\n",
      "Epoch:145, w1:3.0235627524916464, w2:1.4100691680403774, bias:-2.1631151719790367, loss:0.49006592466979765\n",
      "Epoch:146, w1:3.0375770437007104, w2:1.411258643873347, bias:-2.1695363537276706, loss:0.48958620746915343\n",
      "Epoch:147, w1:3.051564855298756, w2:1.4124314861580252, bias:-2.175934529091457, loss:0.4891086526043679\n",
      "Epoch:148, w1:3.065526190882436, w2:1.4135880403036325, bias:-2.1823099544042504, loss:0.48863324554686044\n",
      "Epoch:149, w1:3.079461055311115, w2:1.4147286448189225, bias:-2.188662881525169, loss:0.4881599719864571\n",
      "Epoch:150, w1:3.0933694546801886, w2:1.4158536314538765, bias:-2.1949935579268, loss:0.4876888178248178\n",
      "Epoch:151, w1:3.107251396294905, w2:1.4169633253382639, bias:-2.2013022267815128, loss:0.487219769169108\n",
      "Epoch:152, w1:3.1211068886446856, w2:1.418058045117139, bias:-2.207589127045941, loss:0.4867528123259079\n",
      "Epoch:153, w1:3.1349359413779294, w2:1.4191381030833565, bias:-2.2138544935436673, loss:0.48628793379534513\n",
      "Epoch:154, w1:3.1487385652772963, w2:1.420203805307175, bias:-2.2200985570461547, loss:0.485825120265449\n",
      "Epoch:155, w1:3.162514772235455, w2:1.42125545176302, bias:-2.226321544351966, loss:0.48536435860671\n",
      "Epoch:156, w1:3.1762645752312877, w2:1.422293336453477, bias:-2.2325236783643128, loss:0.48490563586684304\n",
      "Epoch:157, w1:3.189987988306544, w2:1.4233177475305818, bias:-2.238705178166968, loss:0.4844489392657419\n",
      "Epoch:158, w1:3.203685026542932, w2:1.424328967414472, bias:-2.244866259098586, loss:0.48399425619062075\n",
      "Epoch:159, w1:3.217355706039639, w2:1.4253272729094653, bias:-2.251007132825465, loss:0.48354157419133265\n",
      "Epoch:160, w1:3.231000043891275, w2:1.4263129353176263, bias:-2.2571280074127804, loss:0.483090880975859\n",
      "Epoch:161, w1:3.2446180581662256, w2:1.4272862205498804, bias:-2.263229087394339, loss:0.4826421644059653\n",
      "Epoch:162, w1:3.258209767885414, w2:1.4282473892347358, bias:-2.269310573840871, loss:0.48219541249301356\n",
      "Epoch:163, w1:3.2717751930014547, w2:1.4291966968246679, bias:-2.2753726644269094, loss:0.4817506133939278\n",
      "Epoch:164, w1:3.285314354378199, w2:1.430134393700225, bias:-2.2814155534962737, loss:0.4813077554073049\n",
      "Epoch:165, w1:3.29882727377066, w2:1.431060725271907, bias:-2.287439432126202, loss:0.48086682696966626\n",
      "Epoch:166, w1:3.312313973805313, w2:1.4319759320798686, bias:-2.293444488190154, loss:0.48042781665184436\n",
      "Epoch:167, w1:3.325774477960757, w2:1.4328802498915023, bias:-2.2994309064193197, loss:0.47999071315550057\n",
      "Epoch:168, w1:3.3392088105487434, w2:1.4337739097969464, bias:-2.3053988684628584, loss:0.4795555053097647\n",
      "Epoch:169, w1:3.3526169966955472, w2:1.43465713830257, bias:-2.3113485529469027, loss:0.4791221820679983\n",
      "Epoch:170, w1:3.365999062323692, w2:1.4355301574224795, bias:-2.3172801355323474, loss:0.47869073250467\n",
      "Epoch:171, w1:3.379355034134008, w2:1.4363931847680955, bias:-2.323193788971457, loss:0.4782611458123448\n",
      "Epoch:172, w1:3.3926849395880248, w2:1.4372464336358413, bias:-2.329089683163315, loss:0.4778334112987775\n",
      "Epoch:173, w1:3.405988806890688, w2:1.4380901130929897, bias:-2.334967985208141, loss:0.4774075183841103\n",
      "Epoch:174, w1:3.4192666649733963, w2:1.4389244280617097, bias:-2.3408288594605007, loss:0.47698345659816876\n",
      "Epoch:175, w1:3.432518543477353, w2:1.4397495794013526, bias:-2.346672467581432, loss:0.47656121557785275\n",
      "Epoch:176, w1:3.445744472737222, w2:1.4405657639890208, bias:-2.352498968589517, loss:0.47614078506461777\n",
      "Epoch:177, w1:3.458944483765089, w2:1.4413731747984564, bias:-2.3583085189109116, loss:0.4757221549020455\n",
      "Epoch:178, w1:3.472118608234714, w2:1.442172000977288, bias:-2.36410127242837, loss:0.4753053150334978\n",
      "Epoch:179, w1:3.4852668784660796, w2:1.4429624279226752, bias:-2.36987738052927, loss:0.47489025549985286\n",
      "Epoch:180, w1:3.4983893274102185, w2:1.4437446373553824, bias:-2.375636992152678, loss:0.474476966437318\n",
      "Epoch:181, w1:3.511485988634325, w2:1.444518807392324, bias:-2.3813802538354585, loss:0.4740654380753193\n",
      "Epoch:182, w1:3.5245568963071388, w2:1.4452851126176085, bias:-2.3871073097574618, loss:0.47365566073446264\n",
      "Epoch:183, w1:3.537602085184597, w2:1.4460437241521193, bias:-2.3928183017857996, loss:0.47324762482456406\n",
      "Epoch:184, w1:3.5506215905957528, w2:1.4467948097216656, bias:-2.3985133695182355, loss:0.4728413208427489\n",
      "Epoch:185, w1:3.5636154484289504, w2:1.4475385337237312, bias:-2.404192650325707, loss:0.4724367393716124\n",
      "Epoch:186, w1:3.5765836951182575, w2:1.4482750572928573, bias:-2.409856279393997, loss:0.4720338710774449\n",
      "Epoch:187, w1:3.5895263676301443, w2:1.4490045383646852, bias:-2.4155043897645703, loss:0.47163270670851554\n",
      "Epoch:188, w1:3.6024435034504103, w2:1.4497271317386926, bias:-2.4211371123746024, loss:0.4712332370934137\n",
      "Epoch:189, w1:3.61533514057135, w2:1.4504429891396489, bias:-2.426754576096205, loss:0.47083545313944514\n",
      "Epoch:190, w1:3.628201317479156, w2:1.4511522592778197, bias:-2.4323569077748766, loss:0.4704393458310823\n",
      "Epoch:191, w1:3.6410420731415525, w2:1.4518550879079484, bias:-2.437944232267188, loss:0.47004490622846457\n",
      "Epoch:192, w1:3.653857446995658, w2:1.4525516178870392, bias:-2.44351667247772, loss:0.4696521254659491\n",
      "Epoch:193, w1:3.666647478936071, w2:1.4532419892309703, bias:-2.449074349395272, loss:0.46926099475070837\n",
      "Epoch:194, w1:3.679412209303174, w2:1.4539263391699613, bias:-2.454617382128352, loss:0.46887150536137273\n",
      "Epoch:195, w1:3.6921516788716544, w2:1.4546048022029208, bias:-2.46014588793997, loss:0.4684836486467186\n",
      "Epoch:196, w1:3.7048659288392365, w2:1.4552775101506974, bias:-2.4656599822817413, loss:0.4680974160243972\n",
      "Epoch:197, w1:3.71755500081562, w2:1.4559445922082586, bias:-2.471159778827321, loss:0.46771279897970486\n",
      "Epoch:198, w1:3.7302189368116245, w2:1.4566061749958195, bias:-2.476645389505179, loss:0.4673297890643935\n",
      "Epoch:199, w1:3.7428577792285327, w2:1.4572623826089466, bias:-2.4821169245307346, loss:0.4669483778955162\n",
      "Epoch:200, w1:3.7554715708476305, w2:1.4579133366676555, bias:-2.487574492437855, loss:0.46656855715431217\n",
      "Epoch:201, w1:3.7680603548199407, w2:1.4585591563645262, bias:-2.493018200109743, loss:0.4661903185851244\n",
      "Epoch:202, w1:3.780624174656146, w2:1.4591999585118558, bias:-2.4984481528092175, loss:0.4658136539943524\n",
      "Epoch:203, w1:3.7931630742166984, w2:1.459835857587871, bias:-2.5038644542084, loss:0.4654385552494366\n",
      "Epoch:204, w1:3.805677097702111, w2:1.4604669657820173, bias:-2.509267206417825, loss:0.46506501427787544\n",
      "Epoch:205, w1:3.81816628964343, w2:1.4610933930393477, bias:-2.5146565100149822, loss:0.4646930230662699\n",
      "Epoch:206, w1:3.830630694892882, w2:1.4617152471040282, bias:-2.520032464072301, loss:0.4643225736593998\n",
      "Epoch:207, w1:3.8430703586146984, w2:1.4623326335619786, bias:-2.525395166184592, loss:0.4639536581593262\n",
      "Epoch:208, w1:3.855485326276103, w2:1.4629456558826683, bias:-2.5307447124959546, loss:0.46358626872452224\n",
      "Epoch:209, w1:3.867875643638474, w2:1.4635544154600837, bias:-2.5360811977261632, loss:0.46322039756902805\n",
      "Epoch:210, w1:3.880241356748665, w2:1.464159011652884, bias:-2.541404715196541, loss:0.46285603696163274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.880241356748665, 1.464159011652884, -2.541404715196541)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(X_train_scaled['age'],X_train_scaled['affordibility'],y_train,1000, 0.4631)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.9950013],\n",
       "        [0.995001 ]], dtype=float32),\n",
       " array([-0.00499932], dtype=float32))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef, intercept"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
